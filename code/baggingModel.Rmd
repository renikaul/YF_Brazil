---
title: "YF Bagged LogReg Model"
author: "Michelle Evans, Spencer Hall, Reni Kaul, Anna Kate Schatz"
date: "July 12, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load packages}
library(dplyr)
library(gplots)
library(parallel)
library(doParallel)
library(ROCR)
library(pROC)
```

# General Outline of Model

## Load, Combine, and Clean/Format Data

Make sure that there is a row for every muni x year x month, not *only* presences.

Population data is log 10 transformed in Ebola work, after correcting 0 to 1 to avoid NAs with log transformation. Between five year increments were interpolated. Population was then binned.

Original ebola paper used a scaled rainfall value (scaled to maximum of muni, in our case). Also used one that was logged transformed. Looks like they used both at the same time?

EVI and PET were rescaled by subtracting the mean and dividing by sd. In the Ebola paper, these were just averages from 2000 - 2014, so there is only one layer/ So this is the mean of the whole layer (in our case all munis at a year x month).

Data was sorted/stratified by rainfall so that the training/test split was not biased by rainfall levels.

2/3 split for training/testing.

### Scaling of Environmental Covariates

Rainfall is of a similar range (0 -1.5), with an exponential distribution. We normalized in two ways. First we log transformed it. Second, we rescaled to the maximum value of that municipality. This resulted in two values for each type of rainfall, for a total of six.  

```{r rainfall}
rf <- readRDS("../data_clean/environmental/allRainfall.rds")
hist(rf[,5]) #min rainfall exponential with long tail
range(rf[,5])
hist(rf[,6]) #max rainfall, exponential
range(rf[,6])
hist(rf[,7]) #mean rainfall, exponential
range(rf[,7])

#transformed variables

#log transformed
nonzero<-  min(rf[which(rf[,5]>0),5])#what is smallest non-zero value
hist(log((rf[,5])+nonzero/10)) #check that handling zeros is ok

rf$log.min.rf  <- log((rf[,5])+nonzero/10)
rf$log.max.rf  <- log((rf[,6])+nonzero/10)
rf$log.mean.rf  <- log((rf[,7])+nonzero/10) #use this 

#scale to maximum value of muni
rf <- rf %>%
  group_by(muni.no) %>%
  mutate(max.max.rf = max(hourlyRainfallMax)) %>%
  mutate(scale.max.rf= hourlyRainfallMax/max.max.rf) %>%
  mutate(max.min.rf = max(hourlyRainfallMin)) %>%
  mutate(scale.min.rf = hourlyRainfallMin/max.min.rf) %>%
  mutate(max.mean.rf = max(hourlyRainfallMean)) %>%
  mutate(scale.mean.rf = hourlyRainfallMean/max.mean.rf) %>%
  select(-max.max.rf, -max.min.rf, -max.mean.rf) %>%
  ungroup()

rm(nonzero)
```

We will only use anomalous mean rainfall (scale.mean.rf) and mean rainfall (hourlyRainfallMean) for each municipality. 

NDVI data is ranged 0 - 1 and is normally distributed, probably doesn't need rescaling. This doesn't need to be trasformed because it is between 0 - 1 and normally distributed.
```{r ndvi}
ndvi <- readRDS("../data_clean/environmental/allNDVI.rds")
hist(ndvi[,5]) #normal

# ndvi.subset <- ndvi %>%
#   group_by(muni.no) %>%
#   summarise_each(funs(mean,sd)) 
# 
# ndvi.subset <- ndvi.subset[sample(0:5564,1000),]
# 
# plotCI(x=1:999, y=ndvi.subset$NDVI_mean, uiw=ndvi.subset$NDVI_sd, gap=0)


ndvi[which(is.na(ndvi$NDVI)),] #missing values for some of muni.no 291992 Madre de Deus

ndvi <- ndvi %>%
        group_by(muni.no, cal.month) %>%
        mutate(scale.ndvi = NDVI/max(NDVI)) %>%
        mutate(range.ndvi= max(NDVI) - min(NDVI)) %>%
        ungroup()
```


Data was manipulated to capture anomalous mean rainfall (scale.mean.rf) and NDVI (scale.NDVI) for a municipality. Anomalous rainfall was calculated for the entire dataset (168 months). Given NDVI should change with season, we scaled NDVI for values within a given month (14 months). The overall range in NDVI for a municipality and calendar month is right skewed with a mean of `r signif(mean(ndvi$range.ndvi, na.rm = TRUE), digits=2)`. 


Temperature is normally distributed.

```{r temperature}
temp <- readRDS("../data_clean/environmental/allTemperature.rds")
hist(temp$tempMax)
hist(temp$tempMean)
hist(temp$tempMin) #still has errors. Needs to be redone

```


Population Data

Because the range is huge, we log10 transformed (population +1) and then binned based on the 25% and 75% quantiles (approximately). We also need to adjust the population data for the muncipalities that recently became emancipated in 2013 (based on `muniCorrection.Rmd`).

```{r population, eval=F}
# pop <- read.csv("../data_clean/demographic/population-long.csv")
# hist(log10(pop$pop))
# 
# quantile(log10(pop$pop), 1/4)
# quantile(log10(pop$pop), 3/4)
# 
# #add in month.no
# month.noFunc <- function(year, month, startYear, startMonth){
#   yearsPast <- year-startYear
#   monthsPast <- month-startMonth
#   totalMonths <- 12*yearsPast + monthsPast + 1
#   return(totalMonths)
# }
# 
# #adjust munis that were emancipated in 2013
# muniCorrections <- read.csv("../data_raw/demographic/muniCorrections.csv")
# 
# pop$old.no <- pop$muni.no #old.no is muni.no pre-2010
# 
# for (i in 1:nrow(muniCorrections)){
#   pop$old.no[pop$muni.no==muniCorrections$muni.no[i]] <- muniCorrections$old.no[i]
# }
# 
# pop <- pop %>%
#   #sum population from missing munis into their "mother" muni
#   group_by(old.no, year, month) %>%
#   mutate(totPop=sum(pop, na.rm=T)) %>%
#   ungroup() %>%
#   #drop newly emancipated
#   filter(!(muni.no %in% muniCorrections$muni.no)) %>%
#   dplyr::select(-muni.no, -X) %>%
#   mutate(logpop=log10(pop+1)) %>%
#   mutate(logpopBin=case_when(
#     logpop<3.5 ~ "bin1",
#     logpop>5 ~ "bin3",
#     TRUE ~ "bin2"
#   )) %>%
#   filter(month<=12)%>%
#   mutate(month.no=month.noFunc(year=year, month=month, startYear=2001, startMonth=1)) %>%
#   dplyr::rename(cal.month=month, muni.name=muni, muni.no=old.no)
#   
# 
# #because this took so long to run, we save it and just call it in in the future
# saveRDS(pop, "../data_clean/demographic/populationLong.rds")

```

Load formatted pop data

```{r load pop data}
pop <- readRDS("../data_clean/demographic/populationLong.rds")
```



Case Data.

```{r cases}
cases <- readRDS("../data_clean/YFcases/YFlong.rds")

cases <- cases %>%
  #drop annual totals
  filter(cal.month<=12) %>%
  #drop unknown origin totals %>%
  filter(!grepl("ignorado", muni))
```



Combine it all into a giant dataframe!

```{r build df}
all.data <- plyr::join_all(list(ndvi, pop, rf, temp, cases), by=c("muni.no", "month.no"), type="full")

#clean it up
all.data <- all.data %>%
  #drop if doesn't match envCovariates (these are all the ones that were emancipated in 2013)
  filter(!is.na(muni.name)) %>%
  #get only columns we need
  select(muni.no, muni.name, month.no, case, logpopBin, logpop, NDVI,scale.ndvi, log.min.rf:scale.mean.rf, tempMax, tempMean)

#turn NA cases to 'true' zeros
all.data$case[is.na(all.data$case)] <- 0
#all positive cases to 1s
all.data$case[all.data$case>0] <- 1
```

## Testing & Training Split

Need to split into testing and training. Perhaps stratify by years?

```{r splitting}
all.data <- all.data[order(-all.data$case, all.data$month.no),] 

all.pres <- filter(all.data, case==1)
all.bg <- filter(all.data, case==0)

test.pres.inds <- base::sample(nrow(all.pres), ceiling(nrow(all.pres)/3)) #without year stratification
test.pres.inds <- seq(1,nrow(all.pres), by=3) #with year stratification

test.bg.inds <- base::sample(nrow(all.bg), ceiling(nrow(all.bg)/3))


test.pres <- all.pres[test.pres.inds,]
train.pres <- all.pres[-test.pres.inds,]

test.bg <- all.bg[test.bg.inds,]
train.bg <- all.bg[-test.bg.inds,]
```


## Bagging

Function from Ebola:

```{r bagging function}
bagging<-function(form.x.y,training.pres,training.abs,new.data,iterations=32){
  #' JP's bagging function
  #' 
  #' @param form.x.y the formula for model to use
  #' @param training.pres dataframe containing training presence data
  #' @param training.abs dataframe containing training background data
  #' @param new.data new data for each logreg model to predict onto
  #' @param iterations number of cores to use. also maybe has something to do with model iterations???
  #'
  #' @returns predictions on new data as a combination (sum??) of predictions from each logreg model
  predictions<-foreach(m=1:9,.combine='+') %dopar% {
    training_positions.p <- sample(nrow(training.pres),size=10)
    training_positions.b <- sample(nrow(training.abs),size=100)
    train_pos.p<-1:nrow(training.pres) %in% training_positions.p #presence
    train_pos.b<-1:nrow(training.abs) %in% training_positions.b #background
    glm_fit<-glm(form.x.y,data=rbind(training.pres[train_pos.p,],training.abs[train_pos.b,]),family=binomial(logit))
    predict(glm_fit,newdata=new.data,type="response")
  }
  return(predictions)
}
```

Write formula for function (only using means for now)
 **change formula to appropriate colnames**
```{r train model}
glm.formula <- as.formula("case~logpop+NDVI+scale.ndvi+log.mean.rf+scale.mean.rf+tempMean") #use cont pop
```

Predict on training set

```{r predict on training}
training <- rbind(train.pres, train.bg)

cores.to.use <- 3 #change dep on computer
iterations <- 1
cl <- makeCluster(cores.to.use)
registerDoParallel(cl)


output1 <- bagging(form.x.y=glm.formula,training.pres=train.pres,training.abs=train.bg,new.data=training,iterations=iterations)

stopCluster(cl)
```

Test Accuracy on Training

```{r}

output.preds<- output1/(iterations*9)
preds <- prediction(output.preds, training$case)
perf <- performance(preds, "sens", "spec")
plot(perf)

train.auc <- performance(preds, "auc") #0.836
```

Changed the binned population size to cont population size. This increases the training AUC to `r signif(train.auc@y.values[[1]], digits=2)`. Dropping scaled NDVI makes a minor difference. Really, dropping any of the abiotic variables has minimal impact on the AUC. Removing population from the model reduces the AUC to approx. 0.7. I think the model is mostly being driven by the population.  

#Opening the testing data

Predict on Test Set

```{r, eval=FALSE}
testing<-rbind(test.pres,test.bg)

cores.to.use <- 3
iterations <- 1
cl <- makeCluster(cores.to.use)
registerDoParallel(cl)

output2<-bagging(form.x.y=glm.formula,training.pres=train.pres,training.abs=train.bg,new.data=testing,iterations=cores.to.use)

stopCluster(cl)
```

Test Accuracy on Testing Data
```{r, eval=FALSE}
test.preds<- output2/(iterations*9)
preds <- prediction(test.preds, testing$case)
perf <- performance(preds, "sens", "spec")
plot(perf)

test.auc <- performance(preds, "auc") #0.779
```


##Snippets from Ebola code

Example of using above function:

```{r, eval=FALSE}
#write glm formula
glm.formula<-as.formula("pres~rf.ym+evi+pet+rf.scaled+as.factor(pd.yr.binned)")

#predict on training set
training<-rbind(train.pres,train.bg)
output1<-bagging(form.x.y=glm.formula,training.pres=train.pres,training.abs=train.bg,new.data=training,iterations=176)

#predict on testing set
testing<-rbind(test.pres,test.bg)
output2<-bagging(form.x.y=glm.formula,training.pres=train.pres,training.abs=train.bg,new.data=testing,iterations=cores.to.use)
```

Giving it a test with fake data:

```{r, eval=FALSE}
trainTest <- cbind(c(rep(1, 30), rep(0,400)), c(rnorm(30,5,2), rnorm(400,10,4)), c(rnorm(30,100,20), rnorm(400,40,8)), c(rnorm(30,0.5, 0.1), rnorm(400,0.1,0.1)))
trainTest[trainTest<0] <- 0
colnames(trainTest) <- c("pres", "v1", "v2", "v3")
trainTest <- as.data.frame(trainTest)

#split into pres and abs
train.pres <- trainTest[trainTest$pres==1,]
train.abs <- trainTest[trainTest$pres==0,]

glm.formula <- as.formula("pres~v1+v2+v3")

cores.to.use <- 10 #bc my macbook sucks
cl <- makeCluster(cores.to.use)
registerDoParallel(cl)

output1 <- bagging(form.x.y=glm.formula,training.pres=train.pres,training.abs=train.abs,new.data=trainTest,iterations=cores.to.use)

stopCluster(cl) #this worked perfectly (all the positives got 9, and 0s got 0)

```

The bagging model sums up the predictions (in this case 9 of them), which then should be averaged.

After this, they then predicted over all of sub-Saharan Africa:

1. Combined all presence into one df, and all bg into one df

2. did bagged predictions using all p and all bg

3. each iteration was split by year, then run over all the cores, six times each

```{r}
# for (i in 1:12){
#   rf.scaled<-fread("rf.scaled.all.csv",select=((i*32)-31):(i*32)) 
#   rf.ym<-fread("rf.ym.df.csv",select=((i*32)-31):(i*32)) 
#   for (j in 1:32){
#     rf.scaled.step<-rf.scaled.all[,j] #Single year of data
#     rf.ym.step<-rf.ym.all[,j] #Single year of data
#     all.data.step<-as.data.frame(cbind(evi.pet.pd.binned,rf.scaled.step,log10(rf.ym.step+1)))
#     colnames(all.data.step)<-c("evi","pet","pd.yr.binned","rf.scaled","rf.ym")
#     sum<-NULL
#     chunks<-6
#     for (k in 1:chunks){
#       output<-bagging(form.x.y=glm.formula,train.pres=final.p,training.bg=final.b,new.data=all.data.step,iterations=cores.to.use) #what does k do here?? just runs 6 times
#       sum<-sum+output
#     }
#     mean.predict<-sum/(cores.to.use*chunks)
#     writeRDS(mean.predict,file=paste("Bags/predictionsSet",i*j))
#     print(i*j)
#   }
# }
```


