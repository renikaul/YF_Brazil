---
title: "YF Bagged LogReg Model"
author: "Michelle Evans, Spencer Hall, Reni Kaul, Anna Kate Schatz"
date: 
header-includes:
    - \usepackage{gensymb}
output: 
  html_document:
      toc: true
      toc_depth: 3
      toc_float: true
    
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, cache = TRUE)
```

```{r load packages}
library(dplyr)
library(gplots)
library(parallel)
library(doParallel)
library(ROCR)
library(pROC)
```


# General Outline of Model

Goal: Create a map 

## Data Summary

Monthly confirmed cases of yellow fever for each Brazilian Munic\'{i}pio (sub-state administrative units) from 2001 to 2014 were downloaded from the Brazilian government's portal da sa\'{u}de website,\href{http://tabnet.datasus.gov.br}{tabnet} on 05 June 2017. Confirmed cases were reported by the Ministry of Health Notification of Injury Information System (Sianan Net) after positive XYZ test. 

The annual population for each Munic\'{i}pio from 2001 to 2014 was also downloaded from the Brazilian government's portal da sa\'{u}de website,\href{http://tabnet.datasus.gov.br}{tabnet} on 05 June 2017. The estimated population was calculated by the Instituto Brasileiro de Geografia e Estat\'{i}stica (Brazialian Institure of Geography and Statistics)   The annual populations from 2001 to 2010 were intercensorial estimates. Post 2010 used slightly different methods ( methods are in Portuguese and pdf form; working on translation).

Monthly land surface temperature and normalized difference vegetation index (NDVI) data from 2001 through 2014 were downloaded from the NASA Land Processes Distributed Active Archive Center (LPDAAC. The MODIS MOD11C3 product contains monthly temperature data at a 0.05$^{\circ}$ resolution. THE MODIS MOD13A3 product contains monthly NDVI data at a 1 km resolution. Both gridded data products were then aggregated to the municipality level to obtain a monthly spatially averaged temperature and NDVI value for each municipality. Rainfall data was obtained from the NASA GESDISC data archive in the form of data from the Tropical Rainfall Monitoring Mission from 2001 through 2014. The 3B43 product contains an average rainfall rate for each month at a 0.25$^{\circ}$ resolution. We aggregated the gridded data to the municipality level by taking the spatial mean.

Both rainfall and NDVI data were further transformed to create fine-scale environmental variables to better characterize environmental anomalies. Rainfall data were scaled to the maximum value of the municipality for the whole period of 2001 to 2014 and NDVI data were scaled to the maximum value for that specific calendar month for each municipality (i.e. June was scaled with all June values from 2001 - 2014).  

## Processing Environmental Covariates

### Rainfall


```{r rainfall}
rf <- readRDS("../data_clean/environmental/allRainfall.rds")

#distribution of raw rainfall rate
hist(rf$hourlyRainfallMean, main="hourly rainfall") #mean rainfall, exponential

#transformed variables

# create log transformed variable with a correction for zero values
nonzero<-  min(rf$hourlyRainfallMean[which(rf$hourlyRainfallMean>0)])#what is smallest non-zero value
hist(log((rf$hourlyRainfallMean)+nonzero/10), main="Log transformed mean hourly rainfall") #log tranform data after adding an value an order of magnitude smaller than the smallest recorded value

rf$log.mean.rf  <- log((rf$hourlyRainfallMean)+nonzero/10) #use this 

#scale to maximum value of muni
rf <- rf %>%
  group_by(muni.no) %>%
  mutate(scale.mean.rf = hourlyRainfallMean/max(hourlyRainfallMean)) %>% #scale rainfall to muni
  ungroup()

rm(nonzero)
```

Rainfall ranges from (`r signif(range(rf$hourlyRainfallMean), digits=2)`), and is exponentially distribution. The mean rainfall was ln transformed. A second covariate, scaled mean rainfall, was created by scalling rainfall to the maximum value of that municipality. We will only use anomalous mean rainfall (scale.mean.rf) and mean rainfall (log.mean.rf) for each municipality. 

### NDVI

```{r ndvi}
ndvi <- readRDS("../data_clean/environmental/allNDVI.rds")
hist(ndvi$NDVI) #normal

# ndvi.subset <- ndvi %>%
#   group_by(muni.no) %>%
#   summarise_each(funs(mean,sd)) 
# 
# ndvi.subset <- ndvi.subset[sample(0:5564,1000),]
# 
# plotCI(x=1:999, y=ndvi.subset$NDVI_mean, uiw=ndvi.subset$NDVI_sd, gap=0)

#ndvi[which(is.na(ndvi$NDVI)),] #missing values for some of muni.no 291992 Madre de Deus

ndvi <- ndvi %>%
        group_by(muni.no, cal.month) %>%
        mutate(scale.ndvi = NDVI/max(NDVI)) %>% #scale NDVI to muni and month
        mutate(range.ndvi = max(NDVI)- min(NDVI)) %>%
        ungroup()
```


NDVI data ranges from 0 - 1 and is normally distributed. This covariate will be used "as-is", and re-scaled to the maximium observed value for that municipality and month. Given NDVI should change with season, we scaled NDVI for values within a given month (14 months). The overall range in NDVI for a municipality and calendar month is right skewed with a mean of `r signif(mean(ndvi$range.ndvi, na.rm = TRUE), digits=2)`.  There is currently an issue with Madre de Deus (291992) municipality returning NA values. This municipality was never infected, and has been dropped for now.  

### Temperature
Temperature is normally distributed, and was used "as-is".

```{r temperature}
temp <- readRDS("../data_clean/environmental/allTemperature.rds")
hist(temp$tempMean)
```


#### Population Data

Because the range is huge, we log10 transformed (population +1). We also need to adjust the population data for the muncipalities that recently became emancipated in 2013 (based on `muniCorrection.Rmd`).

```{r binned population, eval=FALSE}
pop <- read.csv("../data_clean/demographic/population-long.csv")
hist(log10(pop$pop))

quantile(log10(pop$pop), 1/4)
quantile(log10(pop$pop), 3/4)

#add in month.no
month.noFunc <- function(year, month, startYear, startMonth){
  yearsPast <- year-startYear
  monthsPast <- month-startMonth
  totalMonths <- 12*yearsPast + monthsPast + 1
  return(totalMonths)
}

#adjust munis that were emancipated in 2013
muniCorrections <- read.csv("../data_raw/demographic/muniCorrections.csv")

pop$old.no <- pop$muni.no #old.no is muni.no pre-2010

for (i in 1:nrow(muniCorrections)){
  pop$old.no[pop$muni.no==muniCorrections$muni.no[i]] <- muniCorrections$old.no[i]
}

pop <- pop %>%
  #sum population from missing munis into their "mother" muni
  group_by(old.no, year, month) %>%
  mutate(totPop=sum(pop, na.rm=T)) %>%
  ungroup() %>%
  #drop newly emancipated
  filter(!(muni.no %in% muniCorrections$muni.no)) %>%
  dplyr::select(-muni.no, -X) %>%
  mutate(logpop=log10(pop+1)) %>% #need to account for zero sized muni
  mutate(logpopBin=case_when(
    logpop<3.5 ~ "bin1",
    logpop>5 ~ "bin3",
    TRUE ~ "bin2"
  )) %>%
  filter(month<=12)%>%
  mutate(month.no=month.noFunc(year=year, month=month, startYear=2001, startMonth=1)) %>%
  dplyr::rename(cal.month=month, muni.name=muni, muni.no=old.no)


#because this took so long to run, we save it and just call it in in the future
saveRDS(pop, "../data_clean/demographic/populationLong.rds")

```


```{r load pop data}
pop <- readRDS("../data_clean/demographic/populationLong.rds")
hist(pop$totPop, main="Total population size")
hist(pop$logpop, main="Log10(Total population size + 1)")
```


### Case Data
  There are a total of 117 *infected* municipalities in the entire dataset. See `data_clean/case_sparsity.html` for more details. 

```{r cases}
cases <- readRDS("../data_clean/YFcases/YFlong.rds")

cases <- cases %>%
  #drop annual totals
  filter(cal.month<=12) %>%
  #drop unknown origin totals %>%
  filter(!grepl("ignorado", muni))
```


Combine it all into a giant dataframe!

```{r build df}
all.data <- plyr::join_all(list(ndvi, pop, rf, temp, cases), by=c("muni.no", "month.no"), type="full")

#clean it up
all.data <- all.data %>%
  #drop if doesn't match envCovariates (these are all the ones that were emancipated in 2013)
  filter(!is.na(muni.name)) %>%
  #get only columns we need
  select(muni.no, muni.name, month.no, case, logpop, NDVI,scale.ndvi, log.mean.rf,scale.mean.rf, tempMax, tempMean)

#turn NA cases to 'true' zeros
all.data$case[is.na(all.data$case)] <- 0
#all positive cases to 1s
all.data$case[all.data$case>0] <- 1

#remove 291992 Madre de Deus; issues with NA in NDVI
all.data <- all.data[complete.cases(all.data),]
```

## Model

### Testing & Training Split

Infected municipalities were 70/30 split into training and testing data, stratified by year. Background data was also split 70/30.  

```{r splitting}
all.data <- all.data[order(-all.data$case, all.data$month.no),] 

all.pres <- filter(all.data, case==1)
all.bg <- filter(all.data, case==0)

#Split infected municipalities
#test.pres.inds <- base::sample(nrow(all.pres), ceiling(nrow(all.pres)/3)) #without year stratification
test.pres.inds <- seq(1,nrow(all.pres), by=3) #with year stratification
test.pres <- all.pres[test.pres.inds,]
train.pres <- all.pres[-test.pres.inds,]

#Split background data
test.bg.inds <- base::sample(nrow(all.bg), ceiling(nrow(all.bg)/3))
test.bg <- all.bg[test.bg.inds,]
train.bg <- all.bg[-test.bg.inds,]

training <- rbind(train.pres, train.bg)
testing <- rbind(test.pres, test.bg)
```


### Bagging

Modified function from Ebola work:

```{r bagging function}
bagging<-function(form.x.y,training.pres,training.abs,new.data){
  #' modified JP's bagging function
  #' 
  #' @param form.x.y the formula for model to use
  #' @param training.pres dataframe containing training presence data
  #' @param training.abs dataframe containing training background data
  #' @param new.data new data for each logreg model to predict onto
  #' @param iterations number of cores to use. also maybe has something to do with model iterations???
  #'
  #' @returns predictions on new data as a combination (sum??) of predictions from each logreg model
    training_positions.p <- sample(nrow(training.pres),size=10)
    training_positions.b <- sample(nrow(training.abs),size=100)
    train_pos.p<-1:nrow(training.pres) %in% training_positions.p #presence
    train_pos.b<-1:nrow(training.abs) %in% training_positions.b #background
    glm_fit<-glm(form.x.y,data=rbind(training.pres[train_pos.p,],training.abs[train_pos.b,]),family=binomial(logit))
    glm.coef <- coef(glm_fit)
    predictions <- predict(glm_fit,newdata=new.data,type="response")
  return(list(predictions, glm.coef))
}
```

Write formula for model. The infected municipality is a function of: 

  - log population size for year
  - monthly NDVI
  - monthly NDVI scaled to max value at that location and month
  - log transformed monthly rainfall (ave rate of rainfall per day)
  - monthly mean temperature 

```{r train model}
glm.formula <- as.formula("case~logpop+NDVI+scale.ndvi+log.mean.rf+scale.mean.rf+tempMean") 
```

The model is ran for 100 iterations with a subset of the cases. The subset consists of 10 presences (of the 39 training) and 100 background (of the ~300,000) observations.Each iteration of the model is used to predict on the whole training dataset. This is used to calculate AUC. 

```{r predict on training}

#Set up parallel cores to return 2 lists: 1) predictions, 2) coef of model

cores.to.use <- 1 #change dep on computer
iterations <- 100 #number of low bias models to make

#create class to combine multiple results
multiResultClass <- function(predictions=NULL,coefs=NULL)
{
  me <- list(
    predictions = predictions,
    coefs = coefs
  )

  ## Set the name for the class
  class(me) <- append(class(me),"multiResultClass")
  return(me)
}


cl <- makeCluster(cores.to.use)
registerDoParallel(cl)

trainModel <- foreach(i=1:iterations) %dopar% {
    result <- multiResultClass()
    output1 <- bagging(form.x.y=glm.formula,training.pres=train.pres,training.abs=train.bg,new.data=training)
    result$predictions <-output1[[1]]
    result$coefs <- output1[[2]]
    return(result)
}

stopCluster(cl)

#pull out data in usable fashion
trainingPreds <- do.call(cbind,(lapply(trainModel, '[[', 1)))
trainingCoefs <- do.call(cbind,(lapply(trainModel, '[[', 2)))

```

#### Model preformance on whole training set
   The bagged model returned 100 values for each municipality by month. These values are averaged then compared to the known values.  

```{r training AUC}

output.preds<- apply(trainingPreds, 1, mean)
preds <- prediction(output.preds, training$case)
#perf <- performance(preds, "sens", "spec")
#plot(perf)

perf2 <- performance(preds, "tpr", "fpr")
plot(perf2)

train.auc <- performance(preds, "auc") #~0.91
```

Originally the model was ran with binned populations sized, but have since changed to population size log10 transformed. This increases the training AUC to `r signif(train.auc@y.values[[1]], digits=2)` from ~0.8. Dropping any of the abiotic variables has minimal impact on the AUC. Removing any population variable from the model reduces the AUC to approx. 0.7.

##Variable Importance: Needs development
 
   It seems like municipality population size is driving much of the model preformance, but I would like to explore some of the ways that the covariables interact or are more important in given situations. Generally, what intuition can be learned from this model.  
   
```{r training variable importance, echo=FALSE, eval=FALSE}
trainingCoefs<- t(trainingCoefs)

boxplot(trainingCoefs[,c(2:6)], ylim=c(-50,50))
meanCoefs <- apply(trainingCoefs,1, mean)

```

# Visualizing model

This section is TBD. 

***

## Model prediction of testing data

*DON'T TOUCH UNTIL DONE WITH MODEL DEVELOPMENT*

The predictions for the testing data were made by building a similar bagged model (100 iterations using 10 presences and 100 background), but predicted on the testing data instead of the training data. 

```{r testModel, eval=FALSE}

cores.to.use <- 1
iterations <- 100

#create class to combine multiple results
multiResultClass <- function(predictions=NULL,coefs=NULL)
{
  me <- list(
    predictions = predictions,
    coefs = coefs
  )

  ## Set the name for the class
  class(me) <- append(class(me),"multiResultClass")
  return(me)
}


cl <- makeCluster(cores.to.use)
registerDoParallel(cl)

testModel <- foreach(i=1:iterations) %dopar% {
    result <- multiResultClass()
    output1 <- bagging(form.x.y=glm.formula,training.pres=train.pres,training.abs=train.bg,new.data=testing)
    result$predictions <-output1[[1]]
    result$coefs <- output1[[2]]
    return(result)
}

stopCluster(cl)

#pull out data in usable fashion
testingPreds <- do.call(cbind,(lapply(testModel, '[[', 1)))
testingCoefs <- do.call(cbind,(lapply(testModel, '[[', 2)))

```

```{r test AUC, eval=FALSE}
test.preds<- apply(testingPreds, 1, mean)
preds <- prediction(test.preds, testing$case)
# perf <- performance(preds, "sens", "spec")
# plot(perf)

perf2 <- performance(preds, "tpr", "fpr")
plot(perf2)

test.auc <- performance(preds, "auc") 
```

The model has an AUC of  when predicting the testing data. 



----

#Snippets from Ebola code

Example of using above function:

```{r, eval=FALSE}
#write glm formula
glm.formula<-as.formula("pres~rf.ym+evi+pet+rf.scaled+as.factor(pd.yr.binned)")

#predict on training set
training<-rbind(train.pres,train.bg)
output1<-bagging(form.x.y=glm.formula,training.pres=train.pres,training.abs=train.bg,new.data=training,iterations=176)

#predict on testing set
testing<-rbind(test.pres,test.bg)
output2<-bagging(form.x.y=glm.formula,training.pres=train.pres,training.abs=train.bg,new.data=testing,iterations=cores.to.use)
```

Giving it a test with fake data:

```{r, eval=FALSE}
trainTest <- cbind(c(rep(1, 30), rep(0,400)), c(rnorm(30,5,2), rnorm(400,10,4)), c(rnorm(30,100,20), rnorm(400,40,8)), c(rnorm(30,0.5, 0.1), rnorm(400,0.1,0.1)))
trainTest[trainTest<0] <- 0
colnames(trainTest) <- c("pres", "v1", "v2", "v3")
trainTest <- as.data.frame(trainTest)

#split into pres and abs
train.pres <- trainTest[trainTest$pres==1,]
train.abs <- trainTest[trainTest$pres==0,]

glm.formula <- as.formula("pres~v1+v2+v3")

cores.to.use <- 10 #bc my macbook sucks
cl <- makeCluster(cores.to.use)
registerDoParallel(cl)

output1 <- bagging(form.x.y=glm.formula,training.pres=train.pres,training.abs=train.abs,new.data=trainTest,iterations=cores.to.use)

stopCluster(cl) #this worked perfectly (all the positives got 9, and 0s got 0)






```

The bagging model sums up the predictions (in this case 9 of them), which then should be averaged.

After this, they then predicted over all of sub-Saharan Africa:

1. Combined all presence into one df, and all bg into one df

2. did bagged predictions using all p and all bg

3. each iteration was split by year, then run over all the cores, six times each

```{r}
# for (i in 1:12){
#   rf.scaled<-fread("rf.scaled.all.csv",select=((i*32)-31):(i*32)) 
#   rf.ym<-fread("rf.ym.df.csv",select=((i*32)-31):(i*32)) 
#   for (j in 1:32){
#     rf.scaled.step<-rf.scaled.all[,j] #Single year of data
#     rf.ym.step<-rf.ym.all[,j] #Single year of data
#     all.data.step<-as.data.frame(cbind(evi.pet.pd.binned,rf.scaled.step,log10(rf.ym.step+1)))
#     colnames(all.data.step)<-c("evi","pet","pd.yr.binned","rf.scaled","rf.ym")
#     sum<-NULL
#     chunks<-6
#     for (k in 1:chunks){
#       output<-bagging(form.x.y=glm.formula,train.pres=final.p,training.bg=final.b,new.data=all.data.step,iterations=cores.to.use) #what does k do here?? just runs 6 times
#       sum<-sum+output
#     }
#     mean.predict<-sum/(cores.to.use*chunks)
#     writeRDS(mean.predict,file=paste("Bags/predictionsSet",i*j))
#     print(i*j)
#   }
# }
```


