---
title: "YF Bagged LogReg Model"
author: "Michelle Evans, Spencer Hall, Reni Kaul, Anna Kate Schatz"
date: "July 12, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load packages}
library(dplyr)
library(gplots)
library(parallel)
library(doParallel)
library(ROCR)
library(pROC)
```

# General Outline of Model

## Load, Combine, and Clean/Format Data

Make sure that there is a row for every muni x year x month, not *only* presences.

Population data is log 10 transformed in Ebola work, after correcting 0 to 1 to avoid NAs with log transformation. Between five year increments were interpolated. Population was then binned.

Original ebola paper used a scaled rainfall value (scaled to maximum of muni, in our case). Also used one that was logged transformed. Looks like they used both at the same time?

EVI and PET were rescaled by subtracting the mean and dividing by sd. In the Ebola paper, these were just averages from 2000 - 2014, so there is only one layer/ So this is the mean of the whole layer (in our case all munis at a year x month).

Data was sorted/stratified by rainfall so that the training/test split was not biased by rainfall levels.

2/3 split for training/testing.

### Scaling of Environmental Covariates

Rainfall is of a similar range (0 -1.5), with an exponential distribution. We normalized in two ways. First we log transformed it. Second, we rescaled to the maximum value of that municipality. This resulted in two values for each type of rainfall, for a total of six.  

```{r}
rf <- readRDS("../data_clean/environmental/allRainfall.rds")
hist(rf[,5]) #min rainfall exponential with long tail
range(rf[,5])
hist(rf[,6]) #max rainfall, exponential
range(rf[,6])
hist(rf[,7]) #mean rainfall, exponential
range(rf[,7])

#transformed variables

#log transformed
nonzero<-  min(rf[which(rf[,5]>0),5])#what is smallest non-zero value
hist(log((rf[,5])+nonzero/10)) #check that handling zeros is ok

rf$log.min.rf  <- log((rf[,5])+nonzero/10)
rf$log.max.rf  <- log((rf[,6])+nonzero/10)
rf$log.mean.rf  <- log((rf[,7])+nonzero/10)

#scale to maximum value of muni
rf <- rf %>%
  group_by(muni.no) %>%
  mutate(max.max.rf = max(hourlyRainfallMax)) %>%
  mutate(scale.max.rf= hourlyRainfallMax/max.max.rf) %>%
  mutate(max.min.rf = max(hourlyRainfallMin)) %>%
  mutate(scale.min.rf = hourlyRainfallMin/max.min.rf) %>%
  mutate(max.mean.rf = max(hourlyRainfallMean)) %>%
  mutate(scale.mean.rf = hourlyRainfallMean/max.mean.rf) %>%
  select(-max.max.rf, -max.min.rf, -max.mean.rf) %>%
  ungroup()

rm(nonzero)
```

NDVI data is ranged 0 - 1 and is normally distributed, probably doesn't need rescaling. This doesn't need to be trasformed because it is between 0 - 1 and normally distributed.
```{r}
ndvi <- readRDS("../data_clean/environmental/allNDVI.rds")
hist(ndvi[,5]) #normal

# ndvi.subset <- ndvi %>%
#   group_by(muni.no) %>%
#   summarise_each(funs(mean,sd)) 
# 
# ndvi.subset <- ndvi.subset[sample(0:5564,1000),]
# 
# plotCI(x=1:999, y=ndvi.subset$NDVI_mean, uiw=ndvi.subset$NDVI_sd, gap=0)

```

Temperature is normally distributed.

```{r}
temp <- readRDS("../data_clean/environmental/allTemperature.rds")
hist(temp$tempMax)
hist(temp$tempMean)
hist(temp$tempMin) #still has errors. Needs to be redone

```


Population Data

Because the range is huge, we log10 transformed (population +1) and then binned based on the 25% and 75% quantiles (approximately). We also need to adjust the population data for the muncipalities that recently became emancipated in 2013 (based on `muniCorrection.Rmd`).

```{r, eval=F}
pop <- read.csv("../data_clean/demographic/population-long.csv")
hist(log10(pop$pop))

quantile(log10(pop$pop), 1/4)
quantile(log10(pop$pop), 3/4)

#add in month.no
month.noFunc <- function(year, month, startYear, startMonth){
  yearsPast <- year-startYear
  monthsPast <- month-startMonth
  totalMonths <- 12*yearsPast + monthsPast + 1
  return(totalMonths)
}

#adjust munis that were emancipated in 2013
muniCorrections <- read.csv("../data_raw/demographic/muniCorrections.csv")

pop$old.no <- pop$muni.no #old.no is muni.no pre-2010

for (i in 1:nrow(muniCorrections)){
  pop$old.no[pop$muni.no==muniCorrections$muni.no[i]] <- muniCorrections$old.no[i]
}

pop <- pop %>%
  #sum population from missing munis into their "mother" muni
  group_by(old.no, year, month) %>%
  mutate(totPop=sum(pop, na.rm=T)) %>%
  ungroup() %>%
  #drop newly emancipated
  filter(!(muni.no %in% muniCorrections$muni.no)) %>%
  dplyr::select(-muni.no, -X) %>%
  mutate(logpop=log10(pop+1)) %>%
  mutate(logpopBin=case_when(
    logpop<3.5 ~ "bin1",
    logpop>5 ~ "bin3",
    TRUE ~ "bin2"
  )) %>%
  filter(month<=12)%>%
  mutate(month.no=month.noFunc(year=year, month=month, startYear=2001, startMonth=1)) %>%
  dplyr::rename(cal.month=month, muni.name=muni, muni.no=old.no)
  

#because this took so long to run, we save it and just call it in in the future
saveRDS(pop, "../data_clean/demographic/populationLong.rds")

```

Load formatted pop data

```{r}
pop <- readRDS("../data_clean/demographic/populationLong.rds")
```



Case Data.

```{r}
cases <- readRDS("../data_clean/YFcases/YFlong.rds")

cases <- cases %>%
  #drop annual totals
  filter(cal.month<=12) %>%
  #drop unknown origin totals %>%
  filter(!grepl("ignorado", muni))
```



Combine it all into a giant dataframe!

```{r}
all.data <- plyr::join_all(list(ndvi, pop, rf, temp, cases), by=c("muni.no", "month.no"), type="full")

#clean it up
all.data <- all.data %>%
  #drop if doesn't match envCovariates (these are all the ones that were emancipated in 2013)
  filter(!is.na(muni.name)) %>%
  #get only columns we need
  select(muni.no, muni.name, month.no, case, logpopBin, logpop, NDVI, log.min.rf:scale.mean.rf, tempMax, tempMean)

#turn NA cases to 'true' zeros
all.data$case[is.na(all.data$case)] <- 0
#all positive cases to 1s
all.data$case[all.data$case>0] <- 1
```

## Testing & Training Split

Need to split into testing and training. Perhaps stratify by years?

```{r}
all.data <- all.data[order(-all.data$case, all.data$month.no),] 

all.pres <- filter(all.data, case==1)
all.bg <- filter(all.data, case==0)

test.pres.inds <- base::sample(nrow(all.pres), ceiling(nrow(all.pres)/3)) #without year stratification
test.pres.inds <- seq(1,nrow(all.pres), by=3) #with year stratification

test.bg.inds <- base::sample(nrow(all.bg), ceiling(nrow(all.bg)/3))


test.pres <- all.pres[test.pres.inds,]
train.pres <- all.pres[-test.pres.inds,]

test.bg <- all.bg[test.bg.inds,]
train.bg <- all.bg[-test.bg.inds,]
```


## Bagging

Function from Ebola:

```{r}
bagging<-function(form.x.y,training.pres,training.abs,new.data,iterations=32){
  #' JP's bagging function
  #' 
  #' @param form.x.y the formula for model to use
  #' @param training.pres dataframe containing training presence data
  #' @param training.abs dataframe containing training background data
  #' @param new.data new data for each logreg model to predict onto
  #' @param iterations number of cores to use. also maybe has something to do with model iterations???
  #'
  #' @returns predictions on new data as a combination (sum??) of predictions from each logreg model
  predictions<-foreach(m=1:9,.combine='+') %dopar% {
    training_positions.p <- sample(nrow(training.pres),size=10)
    training_positions.b <- sample(nrow(training.abs),size=100)
    train_pos.p<-1:nrow(training.pres) %in% training_positions.p #presence
    train_pos.b<-1:nrow(training.abs) %in% training_positions.b #background
    glm_fit<-glm(form.x.y,data=rbind(training.pres[train_pos.p,],training.abs[train_pos.b,]),family=binomial(logit))
    predict(glm_fit,newdata=new.data,type="response")
  }
  return(predictions)
}
```

Write formula for function (only using means for now)

```{r}
glm.formula <- as.formula("case~as.factor(logpopBin)+NDVI+log.mean.rf+scale.mean.rf+tempMean")
```

Predict on training set

```{r}
training <- rbind(train.pres, train.bg)

cores.to.use <- 8
iterations <- 1
cl <- makeCluster(cores.to.use)
registerDoParallel(cl)


output1 <- bagging(form.x.y=glm.formula,training.pres=train.pres,training.abs=train.bg,new.data=training,iterations=iterations)

stopCluster(cl)
```

Test Accuracy on Training

```{r}

output.preds<- output1/(iterations*9)
preds <- prediction(output.preds, training$case)
perf <- performance(preds, "sens", "spec")
plot(perf)

train.auc <- performance(preds, "auc") #0.836
```

Predict on Test Set

```{r}
testing<-rbind(test.pres,test.bg)

cores.to.use <- 8
iterations <- 1
cl <- makeCluster(cores.to.use)
registerDoParallel(cl)

output2<-bagging(form.x.y=glm.formula,training.pres=train.pres,training.abs=train.bg,new.data=testing,iterations=cores.to.use)

stopCluster(cl)
```

Test Accuracy on Testing Data
```{r}
test.preds<- output2/(iterations*9)
preds <- prediction(test.preds, testing$case)
perf <- performance(preds, "sens", "spec")
plot(perf)

test.auc <- performance(preds, "auc") #0.779
```

## GBM

JP also recommended we use BRTs to get an idea of the partial dependence plots and such

```{r}

```



Example of using above function:

```{r}
#write glm formula
glm.formula<-as.formula("pres~rf.ym+evi+pet+rf.scaled+as.factor(pd.yr.binned)")

#predict on training set
training<-rbind(train.pres,train.bg)
output1<-bagging(form.x.y=glm.formula,training.pres=train.pres,training.abs=train.bg,new.data=training,iterations=176)

#predict on testing set
testing<-rbind(test.pres,test.bg)
output2<-bagging(form.x.y=glm.formula,training.pres=train.pres,training.abs=train.bg,new.data=testing,iterations=cores.to.use)
```

Giving it a test with fake data:

```{r}
trainTest <- cbind(c(rep(1, 30), rep(0,400)), c(rnorm(30,5,2), rnorm(400,10,4)), c(rnorm(30,100,20), rnorm(400,40,8)), c(rnorm(30,0.5, 0.1), rnorm(400,0.1,0.1)))
trainTest[trainTest<0] <- 0
colnames(trainTest) <- c("pres", "v1", "v2", "v3")
trainTest <- as.data.frame(trainTest)

#split into pres and abs
train.pres <- trainTest[trainTest$pres==1,]
train.abs <- trainTest[trainTest$pres==0,]

glm.formula <- as.formula("pres~v1+v2+v3")

cores.to.use <- 10 #bc my macbook sucks
cl <- makeCluster(cores.to.use)
registerDoParallel(cl)

output1 <- bagging(form.x.y=glm.formula,training.pres=train.pres,training.abs=train.abs,new.data=trainTest,iterations=cores.to.use)

stopCluster(cl) #this worked perfectly (all the positives got 9, and 0s got 0)

```

The bagging model sums up the predictions (in this case 9 of them), which then should be averaged.

After this, they then predicted over all of sub-Saharan Africa:

1. Combined all presence into one df, and all bg into one df

2. did bagged predictions using all p and all bg

3. each iteration was split by year, then run over all the cores, six times each

```{r}
# for (i in 1:12){
#   rf.scaled<-fread("rf.scaled.all.csv",select=((i*32)-31):(i*32)) 
#   rf.ym<-fread("rf.ym.df.csv",select=((i*32)-31):(i*32)) 
#   for (j in 1:32){
#     rf.scaled.step<-rf.scaled.all[,j] #Single year of data
#     rf.ym.step<-rf.ym.all[,j] #Single year of data
#     all.data.step<-as.data.frame(cbind(evi.pet.pd.binned,rf.scaled.step,log10(rf.ym.step+1)))
#     colnames(all.data.step)<-c("evi","pet","pd.yr.binned","rf.scaled","rf.ym")
#     sum<-NULL
#     chunks<-6
#     for (k in 1:chunks){
#       output<-bagging(form.x.y=glm.formula,train.pres=final.p,training.bg=final.b,new.data=all.data.step,iterations=cores.to.use) #what does k do here?? just runs 6 times
#       sum<-sum+output
#     }
#     mean.predict<-sum/(cores.to.use*chunks)
#     writeRDS(mean.predict,file=paste("Bags/predictionsSet",i*j))
#     print(i*j)
#   }
# }
```


